\chapter{Ethical Considerations}
Building a dataset to train machine learning models, it is important to consider the possible ethical consequences because the data that a model is trained on can influence the model's behavior and decisions. If the data is biased or unrepresentative, the model's predictions and decisions may also be biased or unrepresentative. This can lead to unfair or unjust outcomes for individuals or groups of people. \\
We are aware that our personal biases could have influenced the topics and the realities described by the tickets that compose the dataset. We have tried to make the dataset as balanced as possible in terms of gender. \\
In some cases, we inferred prompts to create situations that talk about discrimination at workplaces based on gender, race, disability, religion, or nationality. In these cases, there are several tickets that contain toxic language. \\
Nevertheless, Language Models can create unfair discrimination by perpetuating stereotypes and social biases \cite{abid2021persistent}\cite{lucy-bamman-2021-gender}. Most of our work is based on the use of one of these LMs, so we cannot guarantee that there are no biases due to the original data on which the generative model was trained. Some of these biases result in underrepresented groups, stereotypes, exclusionary norms, unfair discrimination and lower performance by social group\cite{weidinger2021ethical}. 

