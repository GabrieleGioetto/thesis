\subsection{Bayesian Network}
A Bayesian Model is a machine learning algorithm that is built with Bayes Theorem in mind.  It is based on the probability theory and it enables a machine to learn from the data.
\begin{equation}
    p(A|B) = \frac{p(B|A)p(A)}{p(B)}
\end{equation}
Formally, the Bayesian network is a directed graph G = (V,E) with
\begin{itemize}
    \item A feature for each node i appartenente a V
    \item A conditional probability distribution for each edge, so the edge from feature $i$ to $j$ represents $p(x_j| x_i)$
  \end{itemize}
The base version of a Bayesian network works with discrete variables, however there are also implementations that consider also continuous variables [https://www.jair.org/index.php/jair/article/download/11063/26242/] \\
Building a Bayesian network starting from the \textit{Absenteeism at work Data Set} is relatively easy, we calculate the likelihood distribution $p(x\_i|x\_j) \forall x_i, x_j \in D$ for each other feature $x_j$. As a prior we used a dirichlet distribution. 
[https://mbernste.github.io/files/notes/Psuedocounts.pdf]
https://cs.nyu.edu/~roweis/csc412-2004/notes/lec13x.pdf
We then added pseudocounts to the observed counts in the data used to calculate $p(x_j| x_i)$. This technique is used to diminish the overfitting of data. The values we used for pseudocount is $\gamma=1$. \\
Since we learn the conditional probability distribution from our data, the structure of the network or the conditional probabilities may therefore leak some information on an individual in the dataset. In order to provide strong privacy guarantees and minimize
the re-identification risk, we leverage the notion of differential-privacy: we perturb the data adding a noise sampled from a Laplace distribution 
\begin{equation}
    z \sim Laplace \left(0, \frac{2 \cdot n_{features}}{\gamma \cdot \epsilon} \right)
\end{equation}
where $\epsilon$ is the privacy budget for differential privacy, which controls the anonymization level.

\begin{equation}
    Pr[M(X) \in Z] \leq e^{\epsilon} \cdot Pr[M(X') \in Z]
\end{equation}
Once the private Bayesian network is built, we can sample new values for all the nodes in the graph. These generated values will have the same distribution and preserve the consistency and statistical properties of the original dataset up to the noise addition which acts as a de-identification barrier. 
